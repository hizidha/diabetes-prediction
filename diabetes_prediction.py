# -*- coding: utf-8 -*-
"""submission 1: diabetes prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ki25a7l3Mf4XFBwC0px2Hn3ZsW9LFDZL

- Nama Lengkap : Adisaputra Zidha Noorizki
- Username : hi_zidha
- Email : hi.zidha@gmail.com

### Import Dataset

Menggunakan dataset **Diabetes Prediction** oleh Mohammed Mustafa yang dapat diakses melalui [link ini](https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset).
"""

!pip install -q kaggle

"""Upload file **kaggle.json** untuk mentautkan dengan akun Kaggle"""

from google.colab import files
files.upload()

! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets download 'iammustafatz/diabetes-prediction-dataset'

!unzip -o diabetes-prediction-dataset.zip

"""### Data Understanding

Menyimpan dataset sebagai DataFrame di sebuah variabel
"""

import numpy as np
import pandas as pd

df = pd.read_csv('diabetes_prediction_dataset.csv')
df.head()

df.info()

"""Menampilkan data rangkuman statistik deskriptif dari file **spotify_songs.csv**"""

df.describe()

"""Menampilkan data bernilai NaN setiap kolom pada dataset"""

miss_values = df.isna().sum()
print("Jumlah nilai NaN dalam setiap kolom:")
print(miss_values)

"""Menampilkan ada berapa banyak data unik dari setiap kolom pada dataset"""

unique_data = df.nunique()
print("Jumlah nilai unik:")
print(unique_data)

"""Terlihat data pada fitur **gender** terdapat 3 macam, perlunya ditampilkan terlebih dahulu"""

unique_gender = df['gender'].unique()
print("Nilai unik dalam kolom 'Gender':", unique_gender)

"""Dikarenakan ada tiga jenis data pada fitur 'gender' dan namun pada penelitian ini berfokus pada 2 gender saja yaitu 'Female' dan 'Male' saja"""

df = df[df['gender'] != 'Other']

# Melihat berapa jumlah data setiap nilai dalam kolom "diabetes"
diabetes_counts = df['diabetes'].value_counts()

# Menampilkan jumlah data setiap nilai dalam kolom "diabetes"
print(diabetes_counts)

"""Menampilkan ukuran dataset"""

df.shape

"""Cek apakah ada data outliner untuk beberapa kolom yang memiliki kemungkinan, dengan indikator jumlah data unique, yaitu ***age*** , ***bmi*** , ***HbA1c_level*** , ***blood_glucose_level***"""

# Commented out IPython magic to ensure Python compatibility.
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

column = ['age', 'bmi', 'HbA1c_level', 'blood_glucose_level']

fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(13, 6))
fig.suptitle("Identifikasi Data Outliner", fontsize=16)

for i, ax in enumerate(axes.flatten()):
    sns.boxplot(x=df[column[i]], ax=ax)
    ax.set_title("Box Plot {}".format(column[i]))
    ax.set_xlabel("value")
    ax.set_ylabel(column[i])

plt.tight_layout()
plt.show()

"""Dari grafik di atas, dapat disimpulkan bahwa ada **data outliner** di beberapa fitur atau kolom pada dataset, maka dari itu diperlukan proses untuk menghapus outliner"""

Q1 = df.quantile(0.25, numeric_only=True)
Q3 = df.quantile(0.75, numeric_only=True)

# Rentang Interkuartil (IQR)
IQR = Q3 - Q1

# Menghapus outlier berdasarkan IQR
df_cleaned = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]

# Cek ukuran dataset setelah melakukan drop outliers
df_cleaned.shape

unique_data_1 = df_cleaned.nunique()
print("Jumlah nilai unik:")
print(unique_data_1)

"""Dikarenakan setelah proses drop outliers terdapat varian data pada beberapa fitur yang hilang. Maka dapat disimpukan bahwa untuk kasus pada dataset ini, data outliers berisi informasi penting atau representasi dari kejadian langka yang memang valid. Dan analisis dan tahap selanjutnya akan menggunakan data sebelum proses drop outliers dilakukan

#### Univariate Analysis

Mengkategorikan fitur pada dataset menjadi dua bagian, yaitu numerical features dan categorical features.
"""

numerical = ['age', 'hypertension', 'heart_disease', 'bmi', 'HbA1c_level', 'blood_glucose_level', 'diabetes']
categorical = ['gender', 'smoking_history']

# Fitur Gender

feature = categorical[0]
count = df[feature].value_counts()

plt.figure(figsize=(5,5))
count.plot(kind='pie', title=feature, autopct='%1.1f%%');
plt.ylabel('')
plt.show()

# Fitur Smoking History

feature = categorical[1]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
df_smoking_his = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
df_smoking_his['persentase'] = df_smoking_his['persentase'].astype(str) + ' %'
print(df_smoking_his)

plt.figure(figsize=(6,3))
count.plot(kind='bar', title=feature);
plt.show()

"""Menampilkan fitur yang memiliki data berupa numerik"""

df.hist(bins=30, figsize=(20,15))
plt.show()

"""Dapat dilihat bahwa jumlah setiap varian data pada beberapa fitur memiliki gap atau jarak yang begitu besar, maka dari itu akan dilakukan proses undersampling pada **Data Preparation** nantinya

#### Multivariate Analysis

Multivariate Analysis bertujuan untuk mengetahui hubungan antara dua atau lebih variabel pada dataset
"""

multivariate_features = df.select_dtypes(include='object').columns.to_list()
for col in multivariate_features:
    sns.catplot(x=col, y="diabetes", kind="bar", data=df, height=3, aspect=4, palette="Set1")
    plt.title("Nilai Diabetes Relatif terhadap - {}".format(col))

"""Menampilkan hubungan atau korelasi antara fitur-fitur yang bertipe data numerik"""

sns.pairplot(df, diag_kind = 'kde')

plt.figure(figsize=(7, 5))
correlation_matrix = df.corr().round(2)

sns.heatmap(data = correlation_matrix, annot=True, linewidths=0.5)
plt.title("Correlation Matrix untuk Fitur Numerik", size=13)

"""Apabila diamati, ada beberapa kesimpulan yang dapat diambil dari proses analisis di atas antara lain:
1. Hubungan Antar Fitur
  * Terdapat beberapa hubungan positif yang signifikan antara beberapa pasangan fitur, seperti:
    * Usia (age) memiliki korelasi positif yang cukup kuat dengan indeks massa tubuh (bmi) (0.34).
    * Tingkat HbA1c (HbA1c_level) memiliki korelasi positif yang signifikan dengan tingkat glukosa darah (blood_glucose_level) (0.17).
    * Diabetes memiliki korelasi yang kuat dengan HbA1c_level (0.40) dan tingkat glukosa darah (0.42).
  * Namun, sebagian besar korelasi antara fitur-fitur numerik tidak sangat tinggi, yang menunjukkan bahwa fitur-fitur tersebut tidak saling tergantung secara linear.

2. Korelasi dengan Variabel Target (Diabetes):
  * Korelasi antara variabel target (diabetes) dengan variabel prediktor menunjukkan beberapa hubungan yang signifikan:
    * Tingkat HbA1c memiliki korelasi tertinggi dengan diabetes (0.40), menunjukkan bahwa tingkat HbA1c dapat menjadi indikator yang kuat untuk risiko diabetes.
    * Tingkat glukosa darah juga memiliki korelasi yang cukup tinggi dengan diabetes (0.42), menunjukkan hubungan yang kuat antara tingkat glukosa darah dan diabetes.
    * Usia (0.26) dan indeks massa tubuh (0.21) juga memiliki korelasi yang cukup tinggi dengan diabetes, menunjukkan bahwa kedua fitur ini juga dapat digunakan sebagai prediktor risiko diabetes.

## Data Preparation
"""

df.info()

from sklearn.preprocessing import OneHotEncoder

df = pd.concat([df, pd.get_dummies(df['gender'], prefix='gender')],axis=1)
df = pd.concat([df, pd.get_dummies(df['smoking_history'], prefix='smoking_history')],axis=1)
df.drop(['gender','smoking_history'], axis=1, inplace=True)

pd.set_option('display.max_columns', None)
df.head()

diabetes_column = df.pop('diabetes')
df.insert(len(df.columns), 'diabetes', diabetes_column)

df.head()

"""Split dataset menjadi beberapa bagian"""

from sklearn.model_selection import train_test_split

X = df.drop(["diabetes"],axis = 1)
y = df["diabetes"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

print("X_train:", X_train.shape)
print("y_train:", y_train.shape)
print("X_test:", X_test.shape)
print("y_test:", y_test.shape)

"""Proses standarisasi nilai data pada setiap fitur dataset mengacu pada proses mengubah skala nilai pada setiap fitur."""

from sklearn.preprocessing import StandardScaler

numerical1 = ['age', 'hypertension', 'heart_disease', 'bmi', 'HbA1c_level', 'blood_glucose_level']
scaler = StandardScaler()

scaler.fit(X_train[numerical1])
X_train[numerical1] = scaler.transform(X_train.loc[:, numerical1])

X_train[numerical1].head()

X_train[numerical1].describe().round(3)

"""Implementasi Metode RUS (*Random Under Sampling*), di mana merupakan teknik yang digunakan untuk menangani ketidakseimbangan kelas dalam dataset."""

from imblearn.under_sampling import RandomUnderSampler
rus = RandomUnderSampler(random_state=42)

print("Shape X_train:", X_train.shape)
print("Shape y_train:", y_train.shape)

"""Melihat jumlah data untuk setiap kelas pada y_train"""

class_counts = y_train.value_counts()
print("Jumlah data untuk setiap kelas pada y_train:")
print(class_counts)

"""Implementasi RUS pada kelas Mayoritas"""

X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)

print("Shape X_train setelah resampling:", X_train_resampled.shape)
print("Shape y_train setelah resampling:", y_train_resampled.shape)

"""Melihat jumlah data untuk setiap kelas pada y_train_resampled"""

class_counts = y_train_resampled.value_counts()
print("Jumlah data untuk setiap kelas pada y_train_resampled:")
print(class_counts)

"""## Modeling

Studi kasus ini menggunakan tiga (3) macam algoritma antara lain:
1. Random Forest
2. Naive Bayes Gaussian
3. XGBoost
"""

from sklearn.metrics import mean_squared_error
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from xgboost import XGBClassifier

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

"""Implementasi Algoritma Random Forest"""

rf_model = RandomForestClassifier(
    n_estimators=100,
    max_depth=20,
    min_samples_split=10,
    random_state=42
)
rf_model.fit(X_train_resampled, y_train_resampled)
y_pred_train_rf = rf_model.predict(X_train_resampled)

accuracy_rf = accuracy_score(y_train_resampled, y_pred_train_rf)
precision_rf = precision_score(y_train_resampled, y_pred_train_rf)
recall_rf = recall_score(y_train_resampled, y_pred_train_rf)
f1_score_rf = f1_score(y_train_resampled, y_pred_train_rf)

"""Implementasi Algoritma Gaussian Naive Bayes"""

gnb_model = GaussianNB()
gnb_model.fit(X_train_resampled, y_train_resampled)
y_pred_train_gnb = gnb_model.predict(X_train_resampled)

accuracy_gnb = accuracy_score(y_train_resampled, y_pred_train_gnb)
precision_gnb = precision_score(y_train_resampled, y_pred_train_gnb)
recall_gnb = recall_score(y_train_resampled, y_pred_train_gnb)
f1_score_gnb = f1_score(y_train_resampled, y_pred_train_gnb)

"""Implementasi Algoritma XGBoosting"""

xgb_model = XGBClassifier(
    n_estimators=1000,
    learning_rate=0.1,
    max_depth=6,
    min_child_weight=1,
    gamma=0,
    subsample=0.8,
    colsample_bytree=0.8,
    scale_pos_weight=1,
    random_state=42
)
xgb_model.fit(X_train_resampled, y_train_resampled)
y_pred_train_xgb = xgb_model.predict(X_train_resampled)

accuracy_xgb = accuracy_score(y_train_resampled, y_pred_train_xgb)
precision_xgb = precision_score(y_train_resampled, y_pred_train_xgb)
recall_xgb = recall_score(y_train_resampled, y_pred_train_xgb)
f1_score_xgb = f1_score(y_train_resampled, y_pred_train_xgb)

"""## Evaluasi Models"""

df_metrics = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score'])

metrics_rf = {'Model': 'Random Forest',
              'Accuracy': accuracy_rf,
              'Precision': precision_rf,
              'Recall': recall_rf,
              'F1-Score': f1_score_rf}

metrics_gnb = {'Model': 'Gaussian Naive Bayes',
               'Accuracy': accuracy_gnb,
               'Precision': precision_gnb,
               'Recall': recall_gnb,
               'F1-Score': f1_score_gnb}

metrics_xgb = {'Model': 'XGBoost',
               'Accuracy': accuracy_xgb,
               'Precision': precision_xgb,
               'Recall': recall_xgb,
               'F1-Score': f1_score_xgb}

df_rf = pd.DataFrame(metrics_rf, index=[0])
df_gnb = pd.DataFrame(metrics_gnb, index=[0])
df_xgb = pd.DataFrame(metrics_xgb, index=[0])

df_metrics = pd.concat([df_rf, df_gnb, df_xgb], ignore_index=True)

df_metrics.head()

plt.figure(figsize=(10, 6))

# Accuracy
plt.subplot(2, 2, 1)
plt.bar(df_metrics['Model'], df_metrics['Accuracy'], color='blue')
plt.title('Accuracy')
plt.ylim(0, 1)
plt.ylabel('Score')

# Precision
plt.subplot(2, 2, 2)
plt.bar(df_metrics['Model'], df_metrics['Precision'], color='green')
plt.title('Precision')
plt.ylim(0, 1)
plt.ylabel('Score')

# Recall
plt.subplot(2, 2, 3)
plt.bar(df_metrics['Model'], df_metrics['Recall'], color='red')
plt.title('Recall')
plt.ylim(0, 1)
plt.ylabel('Score')

# F1-Score
plt.subplot(2, 2, 4)
plt.bar(df_metrics['Model'], df_metrics['F1-Score'], color='orange')
plt.title('F1-Score')
plt.ylim(0, 1)
plt.ylabel('Score')

plt.tight_layout()
plt.show()